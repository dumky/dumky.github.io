---
title: Behind Google
date: 2003-05-20 17:56:52 +0800
disqus_identifier: 44
disqus_url: http://blog.monstuff.com/archives/000044.html
---

<p>Here is <a href="http://www.computer.org/micro/mi2003/m2022.pdf">a good paper on Google's architecture</a>.<br />
I was wondering why Google needed so many servers (apparently more than 10000) to handle "only" 1000 requests/sec.<br />
It turns out that a single request involves many servers, beside the front-end web server: index servers and document servers, as well as ad servers and spell checking services. In fact, many (apparently around a dozen) index and document servers are involved in handling a query, because of the shear size of the data and the need for it to be replicated (for scalability and reliability): the indexes and web content are split in redundant partitions (that they call shards), and a query is performed in parallel on these shards. Also, boxes are needed for the spidering and indexing itself, but I couldn't find a mention of the number of these.</p>
<p>This <a href="http://technetcast.ddj.com/tnc_play_stream.html?stream_id=420">TechNetCast mp3 stream</a> with Jim Reese (Chief Operations Engineer) and the following <a href="http://technetcast.ddj.com/tnc_play_stream.html?stream_id=421">Q&A</a> goes, with humour, over some of the problems that appear when you manage that many servers (networking issues, heat/power/hosting issues, software consistency on all the boxes) and the strategies they employ to mitigate these.</p>

<p>One of the <a href="http://www7.scu.edu.au/programme/fullpapers/1921/com1921.htm">early papers on Google's anatomy</a> by Sergey Brin and Lawrence Page. It gives a lot of interesting details on the design of the search engine.</p>

<p>Also good reads, <a href="http://www.fastcompany.com/magazine/69/google.html">an analysis of some of Google's success factors</a> and Wired's summary of Google's attitude: <a href="http://www.wired.com/wired/archive/11.01/google_pr.html">"Don't be evil"</a>.</p>

<p>A <a href="http://www.wired.com/news/infostructure/0,1377,58497,00.html">Wired article on GRUB</a>, a search engine that attempts to offload the indexing by distributing it to volunteers (ala Seti@Home and Folding@Home). This could allow a faster indexing of the whole web, but certainly creates issues around the reliability of the built index, as well as other technical problems.<br />
</p>

______________________________________



<p>Via Nauman Leghari's blog ( <a href="http://weblogs.asp.net/nleghari/posts/9569.aspx">http://weblogs.asp.net/nleghari/posts/9569.aspx</a> ), many papers from Google people : <a href="http://labs.google.com/papers.html">http://labs.google.com/papers.html</a></p>

Posted by: <a href="http://blog.monstuff.com/">Dumky</a> at July  1, 2003 04:05 PM


<p>More info on PageRank at <a href="http://pagerank.stanford.edu/">http://pagerank.stanford.edu/</a><br />
Sepandar Kamvar ( <a href="http://www.stanford.edu/~sdkamvar/research.html">http://www.stanford.edu/~sdkamvar/research.html</a> ) is doing some excellent research on speeding up the PageRank computation and personalizing the PageRank results.</p>

<p>I haven't heard more from GRUB ( <a href="http://www.grub.org/">http://www.grub.org/</a> ) since last time, but I wonder were it fits in Josh Gray's analysis of Distributed Computing ( <a href="http://www.clustercomputing.org/content/tfcc-5-1-gray.html">http://www.clustercomputing.org/content/tfcc-5-1-gray.html</a> ).</p>

Posted by: <a href="http://blog.monstuff.com/archives/000044.html">Dumky</a> at July 24, 2003 11:19 AM


<p>A video of a recorded lecture (by Urs Hoelzle) about Google is available: <a href="http://norfolk.cs.washington.edu/htbin-post/unrestricted/mmedia/ondemand_colloq.cgi">http://norfolk.cs.washington.edu/htbin-post/unrestricted/mmedia/ondemand_colloq.cgi</a> (search for Google on that page).<br />
It goes through both a software and a hardware overview.</p>

<p>The video is mirrored at <a href="http://www.uwtv.org/programs/displayevent.asp?rid=1680">http://www.uwtv.org/programs/displayevent.asp?rid=1680</a> and <a href="http://www.researchchannel.org/program/displayevent.asp?rid=1680">http://www.researchchannel.org/program/displayevent.asp?rid=1680</a></p>

Posted by: <a href="http://www.cs.washington.edu/info/videos/asx/colloq/UHoelzle_2002_11_05.asx">Dumky</a> at August 28, 2003 06:46 PM



